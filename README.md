
# **ğŸ©ºğŸ’¡ Disease Symptom Prediction ğŸ’¡ğŸ©º**

## **ğŸ” Overview**
This project utilizes **machine learning** to predict diseases based on input symptoms. By analyzing symptom data, the model aims to assist in early detection and healthcare decision-making.

## **ğŸ“‚ Dataset**
The project uses multiple dataset files that provide detailed information about symptoms, their severity, and precautions for various diseases. The datasets have been preprocessed for **training**, **validation**, and **testing**.

### **ğŸ—‚ï¸ Dataset Files**:
- **Symptom-severity.csv**: Contains a list of symptoms along with their severity levels ğŸ¤’.
- **dataset.csv**: The main dataset with symptoms as features and the corresponding diseases ğŸ©º.
- **symptom_Description.csv**: Provides detailed descriptions of each symptom ğŸ“„.
- **symptom_precaution.csv**: Lists recommended precautions for each symptom ğŸ›¡ï¸.


## **ğŸ¤– Models Used**
Several **machine learning models** were trained on the dataset to predict diseases, achieving high accuracy. The top-performing models are:

- **K-Nearest Neighbors (KNN)** ğŸŒŸ (best accuracy: **99.59%**)
- **Random Forest Classifier** ğŸŒ³ (accuracy: **99.39%**)
- **Decision Tree Classifier** ğŸŒ² (accuracy: **99.39%**)
- **Support Vector Classifier (SVC)** ğŸ§  (accuracy: **92.07%**)
- **Logistic Regression** ğŸ“‰ (accuracy: **90.55%**)

### **ğŸ”§ Model Architecture**:
- **K-Nearest Neighbors (KNN)**: Classifies based on the most similar data points.
- **Random Forest**: An ensemble of decision trees to improve prediction accuracy.
- **Decision Tree**: Constructs a tree where decisions are based on features.
- **Support Vector Classifier (SVC)**: Finds the best hyperplane separating the classes (diseases).
- **Logistic Regression**: A linear model used for classification.

### **âš™ï¸ Data Preprocessing**:
- **Data Cleaning**: Managed missing data and handled inconsistencies.
- **Feature Engineering**: Encoded symptoms into a format suitable for machine learning models.

## **ğŸ“Š Results**
The **K-Nearest Neighbors (KNN)** model achieved the highest accuracy of **99.59%**, with **Random Forest** and **Decision Tree** models closely following at **99.39%**.

- **K-Nearest Neighbors**: 99.59% ğŸŒŸ
- **Random Forest**: 99.39% ğŸŒ³
- **Decision Tree**: 99.39% ğŸŒ²
- **Support Vector Classifier**: 92.07% ğŸ§ 
- **Logistic Regression**: 90.55% ğŸ“‰

## **ğŸš€ Future Improvements**
- **Feature Expansion**: Include additional data, such as demographic factors (age, gender, medical history), to improve model accuracy ğŸ§¬.
- **Model Optimization**: Fine-tune hyperparameters to enhance performance âš™ï¸.
- **Deployment**: Develop a web or mobile app for real-time symptom input and disease prediction ğŸ“±.
